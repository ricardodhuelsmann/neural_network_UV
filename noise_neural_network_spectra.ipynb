{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noise_neural_network_spectra.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardodhuelsmann/neural_network_UV/blob/main/noise_neural_network_spectra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIXeqqjlZ3wW"
      },
      "source": [
        "'''Importar bibliotecas necessárias'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pp\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JzcwGFMEztL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785d73a5-12a0-4197-f1cb-7efdea2fb651"
      },
      "source": [
        "'''Carregar dados de arquivo CSV, e separar fração para treino e teste'''\n",
        "input_data = np.genfromtxt('input_noise.csv', delimiter=';')\n",
        "output_data = np.genfromtxt('output_noise.csv', delimiter=';')\n",
        "print(\"Tamanho de dados de entrada: \", len(input_data))\n",
        "print(\"Tamanho de dados de saída: \", len(output_data))\n",
        "x_train = input_data[1:201]\n",
        "x_test = input_data[201:]\n",
        "print(\"Tamanho de matriz de treino: \", len(x_train))\n",
        "print(\"Tamanho de matriz de teste: \", len(x_test))\n",
        "print(\"Tamanho total de dados de treino: \", x_train.size)\n",
        "print(\"Tamanho total de dados de teste: \", x_test.size)\n",
        "y_train = output_data[1:201]\n",
        "y_test = output_data[201:]\n",
        "input_shape_size = int(x_train.size/len(x_train))\n",
        "print(input_shape_size)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de dados de entrada:  251\n",
            "Tamanho de dados de saída:  251\n",
            "Tamanho de matriz de treino:  200\n",
            "Tamanho de matriz de teste:  50\n",
            "Tamanho total de dados de treino:  80200\n",
            "Tamanho total de dados de teste:  20050\n",
            "401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nT1xJBKZ5ag",
        "outputId": "f3b3fb41-325d-4fd1-e38d-3f2c7abf52b4"
      },
      "source": [
        "print(x_train)\n",
        "print(x_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29255096 0.29888756 0.30523202 ... 0.1369904  0.13131767 0.12583609]\n",
            " [0.2343674  0.23934198 0.24433236 ... 0.11778932 0.11297749 0.10833197]\n",
            " [0.20656228 0.21104711 0.21554557 ... 0.09494868 0.09093096 0.08705766]\n",
            " ...\n",
            " [0.05338902 0.05454143 0.05568591 ... 0.05938308 0.05846818 0.05756   ]\n",
            " [0.0489956  0.05025097 0.0514921  ... 0.05412448 0.05358652 0.05303883]\n",
            " [0.01787901 0.01817495 0.0184674  ... 0.01994953 0.01986731 0.01978278]]\n",
            "[[0.26910829 0.27480817 0.28051901 ... 0.11269749 0.10754153 0.10257168]\n",
            " [0.23964001 0.24482812 0.25002288 ... 0.12167143 0.11725063 0.11297757]\n",
            " [0.15410786 0.15746946 0.16084605 ... 0.09838026 0.09519645 0.09211654]\n",
            " ...\n",
            " [0.16405234 0.16757784 0.17108982 ... 0.05863204 0.05601164 0.05347642]\n",
            " [0.10092166 0.103102   0.10527421 ... 0.05456084 0.05280774 0.05110155]\n",
            " [0.02886257 0.02949166 0.03011774 ... 0.0441485  0.04355243 0.04295786]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73c-fnMVr7TB"
      },
      "source": [
        "'''Configurar parâmetros da rede neural'''\n",
        "# change these values to experiment\n",
        "epochs = 200         # number of times the full data trains the network params\n",
        "batch_size = 200    # the amount of data which goes into the network at once\n",
        "num_neurons = 150     # number of neurons required in middle layer"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lFU4s6GiDNW"
      },
      "source": [
        "''' Criar modelo de rede neural, adicionando camadas, definindo número de neuros, ativação, medidas de erro e otimização'''\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_neurons, input_shape=(input_shape_size, ),  activation='relu'))\n",
        "  model.add(Dense(num_neurons, input_shape=(num_neurons,), activation='relu'))\n",
        "  model.add(Dense(num_neurons, input_shape=(num_neurons,), activation='relu'))\n",
        "  model.add(Dense(2))\n",
        "  print(model.summary())\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFjN5De_jCKK"
      },
      "source": [
        "''' Treinar modelo a partir de parâmetros especificados'''\n",
        "def train_model(X, y, model, epochs, batch_size):\n",
        "  h = model.fit(X, y, validation_split=0.2,\n",
        "               epochs=epochs,\n",
        "               batch_size=batch_size,\n",
        "               verbose=1)\n",
        "  pp.figure(figsize=(15,2.5))\n",
        "  pp.plot(h.history['loss'])\n",
        "  pp.title('Training loss wrt time')\n",
        "  return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXLdVodqvWa7"
      },
      "source": [
        "''' Fazer a previsão de valores a partir de rede treinada e comparar valores com o esperado'''\n",
        "def predict_model(X):\n",
        "  prediction = model.predict(X)\n",
        "  print(\"Valores: \\n\", y_test[:])\n",
        "  print(\"Valores: \\n\", y_test[:]/prediction*100)\n",
        "  print(\"\\nMédia\", np.mean(y_test[:]/prediction*100, axis=0))\n",
        "  print(\"Desvio\", np.std(y_test[:]/prediction*100, axis=0))\n",
        "\n",
        "  print(\"\\nMédia 95%\", np.mean(y_test[:10]/prediction[:10]*100, axis=0))\n",
        "  print(\"Desvio\", np.std(y_test[:10]/prediction[:10]*100, axis=0))\n",
        "\n",
        "  print(\"\\nMédia 75%\", np.mean(y_test[10:20]/prediction[10:20]*100, axis=0))\n",
        "  print(\"Desvio\", np.std(y_test[10:20]/prediction[10:20]*100, axis=0))\n",
        "\n",
        "  print(\"\\nMédia 50%\", np.mean(y_test[20:30]/prediction[20:30]*100, axis=0))\n",
        "  print(\"Desvio\", np.std(y_test[20:30]/prediction[20:30]*100, axis=0))\n",
        "\n",
        "  print(\"\\nMédia 30%\", np.mean(y_test[30:40]/prediction[30:40]*100, axis=0))\n",
        "  print(\"Desvio\", np.std(y_test[30:40]/prediction[30:40]*100, axis=0))\n",
        "\n",
        "  print(\"\\nMédia 5%\", np.mean(y_test[40:]/prediction[40:]*100, axis=0))\n",
        "  print(\"Desvio\", np.std(y_test[40:]/prediction[40:]*100, axis=0))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qPskqFwkYKg"
      },
      "source": [
        "'''Gerar modelo'''\n",
        "model = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tot6ROXTHvGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fad63fc-82fa-40bd-aeda-f4e26b961d7c"
      },
      "source": [
        "'''Treinar modelo'''\n",
        "model = train_model(x_train, y_train, model, epochs, batch_size)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.5498 - accuracy: 0.6687 - val_loss: 0.0868 - val_accuracy: 0.1500\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0696 - accuracy: 0.7688 - val_loss: 0.0681 - val_accuracy: 0.8500\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1129 - accuracy: 0.8062 - val_loss: 0.0603 - val_accuracy: 0.8500\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0958 - accuracy: 0.9312 - val_loss: 0.0522 - val_accuracy: 0.8500\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0393 - accuracy: 0.8750 - val_loss: 0.0554 - val_accuracy: 0.8750\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0509 - accuracy: 0.8375 - val_loss: 0.0549 - val_accuracy: 0.9000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0555 - accuracy: 0.8250 - val_loss: 0.0467 - val_accuracy: 0.9000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0366 - accuracy: 0.8313 - val_loss: 0.0344 - val_accuracy: 0.8750\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0243 - accuracy: 0.8938 - val_loss: 0.0239 - val_accuracy: 0.8250\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0272 - accuracy: 0.9500 - val_loss: 0.0176 - val_accuracy: 0.8250\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0279 - accuracy: 0.8375 - val_loss: 0.0152 - val_accuracy: 0.8250\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0158 - accuracy: 0.8938 - val_loss: 0.0151 - val_accuracy: 0.8250\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - accuracy: 0.9438 - val_loss: 0.0138 - val_accuracy: 0.8500\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0144 - accuracy: 0.9187 - val_loss: 0.0091 - val_accuracy: 0.8250\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0099 - accuracy: 0.9438 - val_loss: 0.0051 - val_accuracy: 0.8250\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - accuracy: 0.8938 - val_loss: 0.0048 - val_accuracy: 0.8000\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - accuracy: 0.8313 - val_loss: 0.0055 - val_accuracy: 0.8250\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0073 - accuracy: 0.9062 - val_loss: 0.0045 - val_accuracy: 0.8250\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - accuracy: 0.9438 - val_loss: 0.0033 - val_accuracy: 0.8250\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - accuracy: 0.9375 - val_loss: 0.0034 - val_accuracy: 0.8250\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0071 - accuracy: 0.8938 - val_loss: 0.0046 - val_accuracy: 0.8250\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - accuracy: 0.8938 - val_loss: 0.0068 - val_accuracy: 0.8250\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - accuracy: 0.9312 - val_loss: 0.0087 - val_accuracy: 0.8250\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0064 - accuracy: 0.9375 - val_loss: 0.0082 - val_accuracy: 0.8250\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - accuracy: 0.9062 - val_loss: 0.0062 - val_accuracy: 0.8250\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - accuracy: 0.9000 - val_loss: 0.0047 - val_accuracy: 0.8250\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - accuracy: 0.9250 - val_loss: 0.0048 - val_accuracy: 0.8250\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - accuracy: 0.9375 - val_loss: 0.0062 - val_accuracy: 0.8250\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - accuracy: 0.9375 - val_loss: 0.0072 - val_accuracy: 0.8250\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - accuracy: 0.9062 - val_loss: 0.0062 - val_accuracy: 0.8250\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - accuracy: 0.9250 - val_loss: 0.0045 - val_accuracy: 0.8250\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - accuracy: 0.9375 - val_loss: 0.0036 - val_accuracy: 0.8250\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9375 - val_loss: 0.0036 - val_accuracy: 0.8250\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - accuracy: 0.9312 - val_loss: 0.0042 - val_accuracy: 0.8250\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - accuracy: 0.9250 - val_loss: 0.0047 - val_accuracy: 0.8250\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - accuracy: 0.9375 - val_loss: 0.0044 - val_accuracy: 0.8250\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - accuracy: 0.9375 - val_loss: 0.0034 - val_accuracy: 0.8250\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0019 - accuracy: 0.9312 - val_loss: 0.0029 - val_accuracy: 0.8250\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - accuracy: 0.9250 - val_loss: 0.0028 - val_accuracy: 0.8250\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - accuracy: 0.9312 - val_loss: 0.0030 - val_accuracy: 0.8500\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 0.9375 - val_loss: 0.0031 - val_accuracy: 0.8250\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 0.9250 - val_loss: 0.0029 - val_accuracy: 0.8250\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - accuracy: 0.9062 - val_loss: 0.0024 - val_accuracy: 0.8500\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - accuracy: 0.9125 - val_loss: 0.0021 - val_accuracy: 0.8500\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - accuracy: 0.9312 - val_loss: 0.0021 - val_accuracy: 0.8500\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 0.9125 - val_loss: 0.0022 - val_accuracy: 0.8500\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 0.9062 - val_loss: 0.0023 - val_accuracy: 0.8500\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - accuracy: 0.9125 - val_loss: 0.0022 - val_accuracy: 0.8500\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - accuracy: 0.9187 - val_loss: 0.0019 - val_accuracy: 0.8500\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - accuracy: 0.9125 - val_loss: 0.0018 - val_accuracy: 0.8500\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - accuracy: 0.9062 - val_loss: 0.0019 - val_accuracy: 0.8500\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - accuracy: 0.9125 - val_loss: 0.0020 - val_accuracy: 0.8500\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - accuracy: 0.9125 - val_loss: 0.0021 - val_accuracy: 0.8500\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 0.9125 - val_loss: 0.0020 - val_accuracy: 0.8500\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 0.9125 - val_loss: 0.0019 - val_accuracy: 0.8500\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - accuracy: 0.9125 - val_loss: 0.0019 - val_accuracy: 0.8750\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - accuracy: 0.9187 - val_loss: 0.0020 - val_accuracy: 0.8750\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - accuracy: 0.9125 - val_loss: 0.0021 - val_accuracy: 0.8750\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - accuracy: 0.9125 - val_loss: 0.0021 - val_accuracy: 0.8750\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - accuracy: 0.9187 - val_loss: 0.0019 - val_accuracy: 0.8750\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - accuracy: 0.9187 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 0.9125 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 0.9125 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 0.9250 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - accuracy: 0.9125 - val_loss: 0.0017 - val_accuracy: 0.8750\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 0.9125 - val_loss: 0.0015 - val_accuracy: 0.8750\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 0.9125 - val_loss: 0.0015 - val_accuracy: 0.8750\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 0.9187 - val_loss: 0.0015 - val_accuracy: 0.8750\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 0.9125 - val_loss: 0.0015 - val_accuracy: 0.8750\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - accuracy: 0.9125 - val_loss: 0.0014 - val_accuracy: 0.9000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - accuracy: 0.9187 - val_loss: 0.0014 - val_accuracy: 0.9000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - accuracy: 0.9187 - val_loss: 0.0013 - val_accuracy: 0.9000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - accuracy: 0.9187 - val_loss: 0.0013 - val_accuracy: 0.9000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.8791e-04 - accuracy: 0.9250 - val_loss: 0.0013 - val_accuracy: 0.9000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.9112e-04 - accuracy: 0.9375 - val_loss: 0.0013 - val_accuracy: 0.9000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.7211e-04 - accuracy: 0.9375 - val_loss: 0.0013 - val_accuracy: 0.9000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.5293e-04 - accuracy: 0.9375 - val_loss: 0.0013 - val_accuracy: 0.9000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.5353e-04 - accuracy: 0.9375 - val_loss: 0.0013 - val_accuracy: 0.9250\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.2775e-04 - accuracy: 0.9375 - val_loss: 0.0013 - val_accuracy: 0.9250\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.2582e-04 - accuracy: 0.9375 - val_loss: 0.0013 - val_accuracy: 0.9250\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.1233e-04 - accuracy: 0.9375 - val_loss: 0.0012 - val_accuracy: 0.9250\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.9778e-04 - accuracy: 0.9375 - val_loss: 0.0012 - val_accuracy: 0.9250\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.9506e-04 - accuracy: 0.9375 - val_loss: 0.0012 - val_accuracy: 0.9250\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.7604e-04 - accuracy: 0.9375 - val_loss: 0.0012 - val_accuracy: 0.9250\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.7190e-04 - accuracy: 0.9375 - val_loss: 0.0012 - val_accuracy: 0.9250\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.5886e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.4848e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.4236e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.2859e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.2469e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.1331e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.0658e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.9924e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.8971e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.8430e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.7443e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.6887e-04 - accuracy: 0.9375 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.6040e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.5393e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.4713e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.3977e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.3411e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.2626e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.2087e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.1362e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.0794e-04 - accuracy: 0.9375 - val_loss: 0.0010 - val_accuracy: 0.9250\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.0156e-04 - accuracy: 0.9375 - val_loss: 9.9484e-04 - val_accuracy: 0.9250\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.9556e-04 - accuracy: 0.9375 - val_loss: 9.8895e-04 - val_accuracy: 0.9250\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.8990e-04 - accuracy: 0.9438 - val_loss: 9.8447e-04 - val_accuracy: 0.9250\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.8389e-04 - accuracy: 0.9438 - val_loss: 9.7571e-04 - val_accuracy: 0.9250\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7876e-04 - accuracy: 0.9438 - val_loss: 9.7130e-04 - val_accuracy: 0.9250\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7284e-04 - accuracy: 0.9438 - val_loss: 9.6720e-04 - val_accuracy: 0.9250\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.6797e-04 - accuracy: 0.9438 - val_loss: 9.6060e-04 - val_accuracy: 0.9250\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.6232e-04 - accuracy: 0.9438 - val_loss: 9.5902e-04 - val_accuracy: 0.9250\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.5752e-04 - accuracy: 0.9438 - val_loss: 9.5608e-04 - val_accuracy: 0.9250\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.5226e-04 - accuracy: 0.9438 - val_loss: 9.5019e-04 - val_accuracy: 0.9250\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.4753e-04 - accuracy: 0.9438 - val_loss: 9.4988e-04 - val_accuracy: 0.9250\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.4251e-04 - accuracy: 0.9438 - val_loss: 9.4821e-04 - val_accuracy: 0.9250\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.3776e-04 - accuracy: 0.9438 - val_loss: 9.4429e-04 - val_accuracy: 0.9250\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.3307e-04 - accuracy: 0.9438 - val_loss: 9.4341e-04 - val_accuracy: 0.9250\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.2836e-04 - accuracy: 0.9438 - val_loss: 9.3986e-04 - val_accuracy: 0.9250\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.2375e-04 - accuracy: 0.9438 - val_loss: 9.3710e-04 - val_accuracy: 0.9250\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.1909e-04 - accuracy: 0.9438 - val_loss: 9.3683e-04 - val_accuracy: 0.9250\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.1466e-04 - accuracy: 0.9438 - val_loss: 9.3193e-04 - val_accuracy: 0.9250\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.1003e-04 - accuracy: 0.9438 - val_loss: 9.2908e-04 - val_accuracy: 0.9250\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.0562e-04 - accuracy: 0.9438 - val_loss: 9.2872e-04 - val_accuracy: 0.9250\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.0104e-04 - accuracy: 0.9438 - val_loss: 9.2524e-04 - val_accuracy: 0.9250\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.9667e-04 - accuracy: 0.9438 - val_loss: 9.2389e-04 - val_accuracy: 0.9250\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.9227e-04 - accuracy: 0.9438 - val_loss: 9.2178e-04 - val_accuracy: 0.9250\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.8815e-04 - accuracy: 0.9438 - val_loss: 9.1980e-04 - val_accuracy: 0.9250\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.8385e-04 - accuracy: 0.9438 - val_loss: 9.2024e-04 - val_accuracy: 0.9250\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.7973e-04 - accuracy: 0.9438 - val_loss: 9.1738e-04 - val_accuracy: 0.9250\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.7544e-04 - accuracy: 0.9438 - val_loss: 9.1527e-04 - val_accuracy: 0.9250\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7129e-04 - accuracy: 0.9438 - val_loss: 9.1483e-04 - val_accuracy: 0.9250\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.6710e-04 - accuracy: 0.9438 - val_loss: 9.1253e-04 - val_accuracy: 0.9250\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.6305e-04 - accuracy: 0.9438 - val_loss: 9.1183e-04 - val_accuracy: 0.9250\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.5888e-04 - accuracy: 0.9438 - val_loss: 9.0919e-04 - val_accuracy: 0.9250\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.5467e-04 - accuracy: 0.9438 - val_loss: 9.0681e-04 - val_accuracy: 0.9250\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.5046e-04 - accuracy: 0.9438 - val_loss: 9.0610e-04 - val_accuracy: 0.9250\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.4628e-04 - accuracy: 0.9438 - val_loss: 9.0150e-04 - val_accuracy: 0.9250\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.4206e-04 - accuracy: 0.9438 - val_loss: 8.9948e-04 - val_accuracy: 0.9250\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.3795e-04 - accuracy: 0.9438 - val_loss: 8.9643e-04 - val_accuracy: 0.9250\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.3380e-04 - accuracy: 0.9438 - val_loss: 8.9400e-04 - val_accuracy: 0.9250\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.2976e-04 - accuracy: 0.9438 - val_loss: 8.9198e-04 - val_accuracy: 0.9250\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.2564e-04 - accuracy: 0.9438 - val_loss: 8.8798e-04 - val_accuracy: 0.9250\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.2159e-04 - accuracy: 0.9438 - val_loss: 8.8687e-04 - val_accuracy: 0.9250\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.1753e-04 - accuracy: 0.9438 - val_loss: 8.8393e-04 - val_accuracy: 0.9250\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.1346e-04 - accuracy: 0.9438 - val_loss: 8.8164e-04 - val_accuracy: 0.9250\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.0934e-04 - accuracy: 0.9438 - val_loss: 8.7925e-04 - val_accuracy: 0.9250\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.0527e-04 - accuracy: 0.9438 - val_loss: 8.7695e-04 - val_accuracy: 0.9250\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.0120e-04 - accuracy: 0.9438 - val_loss: 8.7581e-04 - val_accuracy: 0.9250\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.9714e-04 - accuracy: 0.9438 - val_loss: 8.7276e-04 - val_accuracy: 0.9250\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.9305e-04 - accuracy: 0.9438 - val_loss: 8.7057e-04 - val_accuracy: 0.9250\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8885e-04 - accuracy: 0.9438 - val_loss: 8.6694e-04 - val_accuracy: 0.9250\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.8453e-04 - accuracy: 0.9438 - val_loss: 8.6508e-04 - val_accuracy: 0.9250\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8021e-04 - accuracy: 0.9438 - val_loss: 8.6168e-04 - val_accuracy: 0.9250\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.7574e-04 - accuracy: 0.9438 - val_loss: 8.5764e-04 - val_accuracy: 0.9250\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.7102e-04 - accuracy: 0.9438 - val_loss: 8.5413e-04 - val_accuracy: 0.9250\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.6574e-04 - accuracy: 0.9438 - val_loss: 8.4929e-04 - val_accuracy: 0.9250\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.6000e-04 - accuracy: 0.9438 - val_loss: 8.4474e-04 - val_accuracy: 0.9250\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.5371e-04 - accuracy: 0.9438 - val_loss: 8.3825e-04 - val_accuracy: 0.9250\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.4649e-04 - accuracy: 0.9438 - val_loss: 8.3106e-04 - val_accuracy: 0.9250\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.3908e-04 - accuracy: 0.9438 - val_loss: 8.2354e-04 - val_accuracy: 0.9250\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.3267e-04 - accuracy: 0.9438 - val_loss: 8.1263e-04 - val_accuracy: 0.9250\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 4.2747e-04 - accuracy: 0.9438 - val_loss: 8.0574e-04 - val_accuracy: 0.9250\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.2330e-04 - accuracy: 0.9438 - val_loss: 7.9424e-04 - val_accuracy: 0.9250\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.1956e-04 - accuracy: 0.9438 - val_loss: 7.9176e-04 - val_accuracy: 0.9250\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.1618e-04 - accuracy: 0.9438 - val_loss: 7.8043e-04 - val_accuracy: 0.9250\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.1305e-04 - accuracy: 0.9438 - val_loss: 7.8656e-04 - val_accuracy: 0.9250\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1009e-04 - accuracy: 0.9500 - val_loss: 7.7228e-04 - val_accuracy: 0.9250\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.0731e-04 - accuracy: 0.9438 - val_loss: 7.9060e-04 - val_accuracy: 0.9250\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.0499e-04 - accuracy: 0.9563 - val_loss: 7.6545e-04 - val_accuracy: 0.9250\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.0374e-04 - accuracy: 0.9438 - val_loss: 8.0803e-04 - val_accuracy: 0.9500\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.0513e-04 - accuracy: 0.9563 - val_loss: 7.5252e-04 - val_accuracy: 0.9250\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1299e-04 - accuracy: 0.9312 - val_loss: 8.5083e-04 - val_accuracy: 0.9750\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.3684e-04 - accuracy: 0.9812 - val_loss: 7.1583e-04 - val_accuracy: 0.9250\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.0128e-04 - accuracy: 0.9125 - val_loss: 9.6217e-04 - val_accuracy: 0.9750\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.6737e-04 - accuracy: 0.9875 - val_loss: 6.3644e-04 - val_accuracy: 0.9250\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - accuracy: 0.8938 - val_loss: 0.0013 - val_accuracy: 0.9750\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.7925e-04 - val_accuracy: 0.9250\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0034 - accuracy: 0.8500 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - accuracy: 0.9625 - val_loss: 5.8494e-04 - val_accuracy: 0.9250\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - accuracy: 0.8625 - val_loss: 9.4597e-04 - val_accuracy: 0.9750\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.5237e-04 - accuracy: 0.9875 - val_loss: 0.0010 - val_accuracy: 0.9750\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - accuracy: 0.9937 - val_loss: 5.9441e-04 - val_accuracy: 0.9250\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - accuracy: 0.8750 - val_loss: 0.0011 - val_accuracy: 0.9750\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 0.9937 - val_loss: 8.2335e-04 - val_accuracy: 0.9250\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.4718e-04 - accuracy: 0.9750 - val_loss: 6.0811e-04 - val_accuracy: 0.9250\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 0.8875 - val_loss: 0.0011 - val_accuracy: 0.9750\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - accuracy: 0.9937 - val_loss: 7.4959e-04 - val_accuracy: 0.9250\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.2616e-04 - accuracy: 0.9375 - val_loss: 6.1933e-04 - val_accuracy: 0.9250\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 0.8938 - val_loss: 0.0010 - val_accuracy: 0.9750\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 0.9937 - val_loss: 7.0703e-04 - val_accuracy: 0.9250\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.3672e-04 - accuracy: 0.9312 - val_loss: 6.2955e-04 - val_accuracy: 0.9250\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.3241e-04 - accuracy: 0.8938 - val_loss: 9.6765e-04 - val_accuracy: 0.9750\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 0.9937 - val_loss: 7.0374e-04 - val_accuracy: 0.9250\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.4028e-04 - accuracy: 0.9250 - val_loss: 6.5720e-04 - val_accuracy: 0.9250\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7264e-04 - accuracy: 0.8938 - val_loss: 9.7786e-04 - val_accuracy: 0.9500\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.8513e-04 - accuracy: 0.9937 - val_loss: 7.3953e-04 - val_accuracy: 0.9250\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.3963e-04 - accuracy: 0.9187 - val_loss: 7.1478e-04 - val_accuracy: 0.9250\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x180 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqvi4wFtH8u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d8b1c2-446d-48cc-922e-be290e79afca"
      },
      "source": [
        "'''Avaliar modelo'''\n",
        "predict_model(x_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores: \n",
            " [[0.95 0.95]\n",
            " [0.95 0.75]\n",
            " [0.95 0.5 ]\n",
            " [0.95 0.3 ]\n",
            " [0.95 0.05]\n",
            " [0.95 0.95]\n",
            " [0.95 0.75]\n",
            " [0.95 0.5 ]\n",
            " [0.95 0.3 ]\n",
            " [0.95 0.05]\n",
            " [0.75 0.95]\n",
            " [0.75 0.75]\n",
            " [0.75 0.5 ]\n",
            " [0.75 0.3 ]\n",
            " [0.75 0.05]\n",
            " [0.75 0.95]\n",
            " [0.75 0.75]\n",
            " [0.75 0.5 ]\n",
            " [0.75 0.3 ]\n",
            " [0.75 0.05]\n",
            " [0.5  0.95]\n",
            " [0.5  0.75]\n",
            " [0.5  0.5 ]\n",
            " [0.5  0.3 ]\n",
            " [0.5  0.05]\n",
            " [0.5  0.95]\n",
            " [0.5  0.75]\n",
            " [0.5  0.5 ]\n",
            " [0.5  0.3 ]\n",
            " [0.5  0.05]\n",
            " [0.3  0.95]\n",
            " [0.3  0.75]\n",
            " [0.3  0.5 ]\n",
            " [0.3  0.95]\n",
            " [0.3  0.05]\n",
            " [0.3  0.95]\n",
            " [0.3  0.75]\n",
            " [0.3  0.5 ]\n",
            " [0.3  0.3 ]\n",
            " [0.3  0.05]\n",
            " [0.05 0.95]\n",
            " [0.05 0.75]\n",
            " [0.05 0.5 ]\n",
            " [0.05 0.3 ]\n",
            " [0.05 0.05]\n",
            " [0.05 0.95]\n",
            " [0.05 0.75]\n",
            " [0.05 0.5 ]\n",
            " [0.05 0.3 ]\n",
            " [0.05 0.05]]\n",
            "Valores: \n",
            " [[101.58223456  98.05998507]\n",
            " [101.13120133  92.43609868]\n",
            " [101.58987479  94.82395707]\n",
            " [101.77966248 102.33168103]\n",
            " [100.35750984  53.66810128]\n",
            " [100.9204988   92.49412886]\n",
            " [100.8782644   93.05312141]\n",
            " [100.82979465  89.99136412]\n",
            " [101.55820768 115.29916439]\n",
            " [100.48759925  79.75281083]\n",
            " [101.87357032 100.75172207]\n",
            " [102.6409657  101.78848217]\n",
            " [102.04149289  97.12855853]\n",
            " [101.33706588  96.05988536]\n",
            " [101.11800344 111.02351651]\n",
            " [100.63000759  94.83502299]\n",
            " [102.4910559  101.1122587 ]\n",
            " [101.22816536  95.59430838]\n",
            " [100.74532687  92.84135605]\n",
            " [100.88687746  63.03523702]\n",
            " [102.3114142   98.12156127]\n",
            " [100.87997812  95.16559481]\n",
            " [101.02981398  93.77961353]\n",
            " [101.90448447  95.83084363]\n",
            " [100.93687733  65.93798345]\n",
            " [100.83011741  95.08547778]\n",
            " [102.23495395 101.50242876]\n",
            " [100.41239354  90.98921691]\n",
            " [100.59361882  82.44025652]\n",
            " [102.09310379 127.7239973 ]\n",
            " [105.94820433 100.29240203]\n",
            " [105.78397006 104.16348061]\n",
            " [104.23311336 103.95747124]\n",
            " [107.04041042  98.71979422]\n",
            " [101.40589134  65.50122167]\n",
            " [102.2774801   95.6132459 ]\n",
            " [102.87694027  98.71517957]\n",
            " [ 99.63804049  89.59574825]\n",
            " [101.57302464  91.2551046 ]\n",
            " [102.61845463 162.3890149 ]\n",
            " [100.83408373 108.87274073]\n",
            " [ 94.84011306 104.11428474]\n",
            " [134.07258102 111.817968  ]\n",
            " [111.97618876  96.93849259]\n",
            " [ 83.63192259  54.55320849]\n",
            " [ 76.68247991 102.68054281]\n",
            " [102.93016827 105.31947857]\n",
            " [109.69044085 103.96742441]\n",
            " [117.92350604 103.42408827]\n",
            " [113.37619097 207.99216367]]\n",
            "\n",
            "Média [102.37374679  98.45081579]\n",
            "Desvio [ 7.33410926 22.96460789]\n",
            "\n",
            "Média 95% [101.11148478  91.19104127]\n",
            "Desvio [ 0.47167807 15.20741541]\n",
            "\n",
            "Média 75% [101.49925314  95.41703478]\n",
            "Desvio [ 0.68304164 11.84896518]\n",
            "\n",
            "Média 50% [101.32267556  94.6576974 ]\n",
            "Desvio [ 0.69103235 14.63681225]\n",
            "\n",
            "Média 30% [103.33955296 101.0202663 ]\n",
            "Desvio [ 2.22930234 23.04882221]\n",
            "\n",
            "Média 5% [104.59576752 109.96803923]\n",
            "Desvio [15.92094532 36.11334556]\n"
          ]
        }
      ]
    }
  ]
}